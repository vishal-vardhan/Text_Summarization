{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":175,"outputs":[{"output_type":"stream","text":"/kaggle/input/text-summarization-sample/temp.txt\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"ls","execution_count":174,"outputs":[{"output_type":"stream","text":"__notebook_source__.ipynb\r\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.corpus import stopwords\nfrom nltk.cluster.util import cosine_distance\nimport networkx as nx","execution_count":140,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_data(filename):\n    f = open(filename,'r')\n    text = f.read()\n    lines = text.split(\". \")\n    input_data = []\n    maxL = 0\n    for line in lines:\n        for word in line:\n            word = word.lower()\n        if line:\n            t = line.replace(\"[^a-zA-Z]\", \" \").split(\" \")\n            maxL = max(maxL,len(t))\n            input_data.append(t)\n        \n    input_data.pop()\n    \n    return input_data,lines,maxL   \n    \n","execution_count":232,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def sentence_similarity(sent1, sent2, stopwords=None):\n    if stopwords is None:\n        stopwords = []\n \n    sent1 = [w.lower() for w in sent1]\n    sent2 = [w.lower() for w in sent2]\n \n    all_words = list(set(sent1 + sent2))\n \n    vector1 = [0] * len(all_words)\n    vector2 = [0] * len(all_words)\n \n    for w in sent1:\n        if w in stopwords:\n            continue\n        vector1[all_words.index(w)] += 1\n \n    for w in sent2:\n        if w in stopwords:\n            continue\n        vector2[all_words.index(w)] += 1\n \n    return 1 - cosine_distance(vector1, vector2)","execution_count":142,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def similarity_matrix(input_data,stop_words):\n    n = len(input_data)\n    matrix = np.zeros((n,n))\n    \n    for i in range(n):\n        for j in range(n):\n            if i==j:\n                continue\n            matrix[i][j] = sentence_similarity(input_data[i],input_data[j],stop_words)\n    \n    return matrix","execution_count":143,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def Summary_PageRank(input_text,top_n=2):\n    \n    input_data,lines,maxL = get_data(input_text)\n    n = len(input_data)\n    if n>(3*top_n):\n        top_n = int(n/3)\n    stop_words = stopwords.words('english')\n    input_data_mat = similarity_matrix(input_data,stop_words)\n    \n    sentence_similarity_graph = nx.from_numpy_array(input_data_mat)\n    scores = nx.pagerank(sentence_similarity_graph)\n\n    # Step 4 - Sort the rank and pick top sentences\n    ranked_sentence = sorted(((scores[i],s) for i,s in enumerate(input_data)), reverse=True)    \n    #print(\"Indexes of top ranked_sentence order are \", ranked_sentence)  \n    summarize_text = []\n    for i in range(top_n):\n      summarize_text.append(\" \".join(ranked_sentence[i][1]))\n\n    # Step 5 - Offcourse, output the summarize texr\n    print(\"Summarize Text: \\n\", \". \".join(summarize_text))\n    ","execution_count":187,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Summary_PageRank(\"/kaggle/input/text-summarization-sample/temp.txt\")","execution_count":188,"outputs":[{"output_type":"stream","text":"Summarize Text: \n Last fall, we started a digital fiction series, publishing to the Amazon Kindle two short stories a month by authors like Christopher Buckley, Curtis Sittenfeld, and Paul Theroux. he short story has been integral to The Atlantic since our first issue, in 1857, in which we published four stories, including “The Mourning Veil,” by Harriet Beecher Stowe. All told, The Atlantic is now publishing more fiction than it has since the mid-1970s.But I should admit that these fiction initiatives are experimental, provisional, part of our larger adventure through the seismically shifting landscape of letters. For the Web site each day, we produce dozens of posts analyzing breaking developments in politics, business, culture, technology, and other subjects, some of them longtime preoccupations of The Atlantic, others fairly new to all of us. But none of us has been particularly happy with it, and we have been searching for ways to once again place great fiction in front of all our readers.With our fiction issue last year, we began a partnership with Luminato, the Toronto Festival of Arts and Creativity, which shares our love of literature. But as longtime, generously loyal readers know, for the past five years we have published fiction once a year in a special newsstand issue, rather than in any of our 10 subscriber issues\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def nextPowerOf2(n): \n    count = 0; \n    \n    if (n and not(n & (n - 1))): \n        return n \n      \n    while( n != 0): \n        n >>= 1\n        count += 1\n      \n    return 1 << count","execution_count":189,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nextPowerOf2(6)","execution_count":148,"outputs":[{"output_type":"execute_result","execution_count":148,"data":{"text/plain":"8"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\n\nfrom tensorflow import keras\nimport tensorflow as tf\n\n","execution_count":190,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def text_encode(input_data,n):\n    m = len(input_data)\n    tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words = m*n,filters='')\n    tokenizer.fit_on_texts(input_data)\n    \n    seq = tokenizer.texts_to_sequences(input_data)\n    input_data = tf.keras.preprocessing.sequence.pad_sequences(seq,maxlen = n)\n    display(input_data)\n    return input_data,tokenizer","execution_count":191,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.cluster import KMeans\nfrom scipy.spatial import distance\n","execution_count":192,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_k(input_data,lines,k=2):    \n    \n    n = len(input_data)\n    print(n)\n    if n>(3*k):\n        k = int(n/3)\n    \n    kmeans = KMeans(k,init = 'k-means++',random_state = 42)\n    y_kmeans = kmeans.fit_predict(input_data)\n    \n    res = []\n    for i in range(k):\n        my_dict = {}\n        for j in range(len(y_kmeans)):\n            if y_kmeans[j] == i:\n                my_dict[j] =  distance.euclidean(kmeans.cluster_centers_[i],input_data[j])\n        if my_dict:\n            minDist = min(my_dict.values())\n            res.append(min(my_dict,key = my_dict.get))\n    print(res)\n    result = []\n    \n    for i in sorted(res):\n        result.append(lines[i])\n        \n    return result","execution_count":244,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def Summary_Enc_Dec_Kmeans(filename):\n    input_data,lines,n = get_data(filename)\n    m = len(input_data)\n    stop_words = stopwords.words('english')\n    \n    n = nextPowerOf2(n)\n    encoded_input,tokenizer = text_encode(input_data,n)\n    output = get_k(encoded_input,lines)\n    return '. '.join(output)  \n    \n    \n    \n    ","execution_count":234,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nSummary_Enc_Dec_Kmeans(\"/kaggle/input/text-summarization-sample/temp.txt\")","execution_count":245,"outputs":[{"output_type":"display_data","data":{"text/plain":"array([[  0,   0,   0, ...,  74,  75,  76],\n       [  0,   0,   0, ...,  88,  89,  90],\n       [  0,   0,   0, ...,   8, 101, 102],\n       ...,\n       [  0,   0,   0, ...,  23,   2,  43],\n       [  0,   0,   0, ..., 307, 308, 309],\n       [  0,   0,   0, ...,   2, 323, 324]], dtype=int32)"},"metadata":{}},{"output_type":"stream","text":"18\n[0, 13, 8, 17, 16, 15]\n","name":"stdout"},{"output_type":"execute_result","execution_count":245,"data":{"text/plain":"['he short story has been integral to The Atlantic since our first issue, in 1857, in which we published four stories, including “The Mourning Veil,” by Harriet Beecher Stowe',\n 'If our hardworking developers have pulled it off, by the time you read this note our Web site, TheAtlantic.com, will have relaunched with a new design and a superior system for finding the subjects you’re interested in and discovering new ideas you didn’t know you were looking for',\n 'For our print magazine and our e-reader editions, we are continuing to devote months of reporting and writing to create pieces like Joshua Green’s profile in this issue of Treasury Secretary Timothy Geithner, and Robert D',\n 'For the Web site each day, we produce dozens of posts analyzing breaking developments in politics, business, culture, technology, and other subjects, some of them longtime preoccupations of The Atlantic, others fairly new to all of us',\n 'As I write, on our site I can see posts popping up by James Fallows about Twitter, by Andrew Sullivan about the future of gays in the military, and by Ta-Nehisi Coates about the moral courage of Civil War General George Henry Thomas',\n 'What matters to us—in all the work that we do, on whatever platform may present itself—is the quality and consequence of an idea, and the clarity and power of its expression']"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}